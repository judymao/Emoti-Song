{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMFDB Data - Preliminary\n",
    "\n",
    "Organize the data into labelled folders, separated by training, test, and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_IMFDB(raw_data_path):\n",
    "    \"\"\"\n",
    "    To clean the IMFDB data, we need to do the following:\n",
    "    \n",
    "    - remove Disgust and Surprise datasets\n",
    "    - split into each label\n",
    "    - split into training, test, and validation datasets\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    allowed_emotions = ['HAPPINESS', 'NEUTRAL', 'SADNESS', 'FEAR', 'ANGER']\n",
    "    emotion_mapping = {'HAPPINESS':'Happy', 'NEUTRAL':'Neutral', 'SADNESS':'Sad', 'FEAR':'Fear','ANGER':'Anger'}\n",
    "\n",
    "    # Organize images into: label/dataset folders, where label is an allowed emotion and dataset is train/validation/test\n",
    "\n",
    "    random.seed(50)\n",
    "\n",
    "    # First divide actors into train/validation/test\n",
    "    actors = os.listdir(IMFDB_raw_path)\n",
    "    random.shuffle(actors)\n",
    "\n",
    "    actor_dict = {}\n",
    "    train_actors = actors[:int(len(actors)*0.8)] # 80% test dataset\n",
    "    validation_actors = actors[int(len(actors)*0.8):int(len(actors)*0.9)] # 10% validation dataset\n",
    "    test_actors = actors[int(len(actors)*0.9):] # 10% validation dataset\n",
    "\n",
    "    for actor in train_actors:\n",
    "        actor_dict[actor] = 'training'\n",
    "\n",
    "    for actor in validation_actors:\n",
    "        actor_dict[actor] = 'validation'\n",
    "\n",
    "    for actor in test_actors:\n",
    "        actor_dict[actor] = 'test'\n",
    "\n",
    "    # Iterate through each actor\n",
    "    for actor in os.listdir(raw_data_path):\n",
    "        # Iterate through each movie\n",
    "        for movie in os.listdir(os.path.join(raw_data_path, actor)):\n",
    "            text_file = os.path.join(raw_data_path, actor, movie, movie+'.txt')\n",
    "            image_folder = os.path.join(raw_data_path, actor, movie, 'images')\n",
    "\n",
    "\n",
    "            try:\n",
    "                data = pd.read_csv(text_file, header=None, sep='\\t').rename({1:'image', 10:'emotion'}, axis=1)\n",
    "\n",
    "                i = 1 # Find the emotion column\n",
    "                while data.iloc[0,i+9] not in ['HAPPINESS', 'NEUTRAL', 'SADNESS', 'FEAR', 'ANGER', 'SURPRISE', 'DISGUST'] and i < len(data.columns)-1:\n",
    "                    data = data.rename({'image':i, i+1:'image','emotion':i+9,i+10:'emotion'}, axis=1)\n",
    "                    i+=1\n",
    "\n",
    "                emotion_dict = dict(zip(data.image, data.emotion))\n",
    "\n",
    "                for image_file in os.listdir(image_folder):\n",
    "                    if image_file in emotion_dict.keys() and emotion_dict[image_file] in allowed_emotions:\n",
    "                        # copy to new folder\n",
    "                        shutil.copy(os.path.join(image_folder,image_file), os.path.join(os.getcwd(), 'data_IMFDB',\n",
    "                                                                                        actor_dict[actor], \n",
    "                                                                                        emotion_mapping[emotion_dict[image_file]],\n",
    "                                                                                        image_file))\n",
    "            except:\n",
    "                print(data.head())\n",
    "                print(actor, movie, sys.exc_info()[0])\n",
    "    \n",
    "    print(\"Data successfully moved from raw files folder split by actor and movie to label folders split by training, validation, and testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMFDB Data - Cleaning\n",
    "\n",
    "Loading into datasets and applying cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "def clean_IMFDB(raw_data_path):\n",
    "    \"\"\"\n",
    "    To clean the IMFDB data, we need to do the following:\n",
    "    \n",
    "    - resize datasets to 48x48 pixels\n",
    "    - convert to greyscale (1 channel)\n",
    "    - normalize the pixel values\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(48), # Change dimensions to 48x48\n",
    "        transforms.CenterCrop(48), # Convert to square aspect\n",
    "        transforms.ToTensor() # Convert pixels to 0-1 range\n",
    "    ])\n",
    "\n",
    "    train_datasets = torchvision.datasets.ImageFolder(root=os.path.join(raw_data_path,'training'),\n",
    "                                                      transform=data_transforms)\n",
    "    val_datasets = torchvision.datasets.ImageFolder(root=os.path.join(raw_data_path,'validation'),\n",
    "                                                    transform=data_transforms)\n",
    "    test_datasets = torchvision.datasets.ImageFolder(root=os.path.join(raw_data_path,'test'),\n",
    "                                                     transform=data_transforms)\n",
    "    \n",
    "    return train_datasets, val_datasets, test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMFDB_raw_path = os.path.join(os.getcwd(), \"raw_facial_data_IMFDB\")\n",
    "# org_IMFDB(IMFDB_raw_path)\n",
    "\n",
    "IMFDB_path = os.path.join(os.getcwd(), \"data_IMFDB\")\n",
    "IMFDB_train, IMFDB_val, IMFDB_test = clean_IMFDB(IMFDB_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IMFDB training images:  16392\n",
      "Number of IMFDB validation images:  2147\n",
      "Number of IMFDB test images:  2170\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of IMFDB training images: \", len(IMFDB_train))\n",
    "print(\"Number of IMFDB validation images: \", len(IMFDB_val))\n",
    "print(\"Number of IMFDB test images: \", len(IMFDB_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger', 'Fear', 'Happy', 'Neutral', 'Sad']\n",
      "Number of train images in each class {0: 1975, 1: 471, 2: 5566, 3: 5859, 4: 2521}\n",
      "Number of validation images in each class {0: 307, 1: 79, 2: 566, 3: 940, 4: 255}\n",
      "Number of test images in each class {0: 213, 1: 17, 2: 651, 3: 855, 4: 434}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_counts = dict(Counter(sample_tup[1] for sample_tup in IMFDB_train))\n",
    "val_counts = dict(Counter(sample_tup[1] for sample_tup in IMFDB_val))\n",
    "test_counts = dict(Counter(sample_tup[1] for sample_tup in IMFDB_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger', 'Fear', 'Happy', 'Neutral', 'Sad']\n",
      "Number of train images in each IMFDB class \t\t {0: 1975, 1: 471, 2: 5566, 3: 5859, 4: 2521}\n",
      "Number of validation images in each IMFDB class \t {0: 307, 1: 79, 2: 566, 3: 940, 4: 255}\n",
      "Number of test images in each IMFDB class \t\t {0: 213, 1: 17, 2: 651, 3: 855, 4: 434}\n"
     ]
    }
   ],
   "source": [
    "print(IMFDB_train.classes)\n",
    "print('Number of train images in each IMFDB class \\t\\t', train_counts)\n",
    "print('Number of validation images in each IMFDB class \\t', val_counts)\n",
    "print('Number of test images in each IMFDB class \\t\\t', test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_array(row, normalize=False):\n",
    "    \"\"\"\n",
    "    Convert a string space-separated pixel values in row major order into a 2D numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert into 1D numpy array\n",
    "    arr_1D = np.fromstring(row, dtype=int, sep=\" \")\n",
    "    \n",
    "    # Convert into 2D numpy array with 48 x 48 shape\n",
    "    arr_2D = np.reshape(arr_1D, (48, 48))\n",
    "    \n",
    "    if normalize:\n",
    "        arr_2D = arr_2D/255\n",
    "    \n",
    "    return arr_2D\n",
    "    \n",
    "def clean_Kaggle(raw_data_path):\n",
    "    \"\"\"\n",
    "    To clean the Kaggle data, we need to do the following:\n",
    "    \n",
    "    - remove Disgust and Surprise datasets\n",
    "    - normalize the pixels\n",
    "    - set training data to training data\n",
    "    - set public test data to validation data\n",
    "    - set private test data to test data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    kaggle_raw = pd.read_csv(kaggle_raw_path)\n",
    "    \n",
    "    # Remove disgust (1) and surprise(5) data\n",
    "    kaggle_df = kaggle_raw.loc[(kaggle_raw.emotion != 1) & (kaggle_raw.emotion != 5)]\n",
    "    \n",
    "    emotion_labels = {0:0, 2:1, 3:2, 4:4, 6:3}\n",
    "    kaggle_df = kaggle_df.replace(emotion_labels)\n",
    "\n",
    "    # Convert pixel values from space-separted pixel values in row major order to numpy arrays and normalize\n",
    "    # Return as tensors\n",
    "    kaggle_df['normalized_pixels'] = kaggle_df[' pixels'].apply(lambda row: convert_str_to_array(row, normalize=True))\n",
    "    \n",
    "    # Split into training, validation, and test datasets\n",
    "    train_df = kaggle_df[['emotion', 'normalized_pixels']].loc[kaggle_df[' Usage']=='Training']\n",
    "    val_df = kaggle_df[['emotion', 'normalized_pixels']].loc[kaggle_df[' Usage']=='PublicTest']\n",
    "    test_df = kaggle_df[['emotion', 'normalized_pixels']].loc[kaggle_df[' Usage']=='PrivateTest']\n",
    "    \n",
    "    train_values = train_df.normalized_pixels.values\n",
    "    print(train_values)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.2039, 0.2314, 0.2549,  ..., 0.0902, 0.0824, 0.0784],\n",
      "         [0.1608, 0.2000, 0.2314,  ..., 0.0980, 0.0902, 0.0863],\n",
      "         [0.1137, 0.1569, 0.2039,  ..., 0.1098, 0.1020, 0.0980],\n",
      "         ...,\n",
      "         [0.1059, 0.1294, 0.1569,  ..., 0.1608, 0.1608, 0.1608],\n",
      "         [0.0706, 0.1059, 0.1451,  ..., 0.1529, 0.1529, 0.1569],\n",
      "         [0.0667, 0.1020, 0.1412,  ..., 0.1529, 0.1529, 0.1529]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "for i in IMFDB_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.2745098 , 0.31372549, 0.32156863, ..., 0.20392157, 0.16862745,\n",
      "        0.16078431],\n",
      "       [0.25490196, 0.23921569, 0.22745098, ..., 0.21960784, 0.20392157,\n",
      "        0.17254902],\n",
      "       [0.19607843, 0.16862745, 0.21176471, ..., 0.19215686, 0.21960784,\n",
      "        0.18431373],\n",
      "       ...,\n",
      "       [0.35686275, 0.25490196, 0.16470588, ..., 0.28235294, 0.21960784,\n",
      "        0.16862745],\n",
      "       [0.30196078, 0.32156863, 0.30980392, ..., 0.41176471, 0.2745098 ,\n",
      "        0.18039216],\n",
      "       [0.30196078, 0.28235294, 0.32941176, ..., 0.41568627, 0.42745098,\n",
      "        0.32156863]])\n",
      " array([[0.59215686, 0.58823529, 0.57647059, ..., 0.50588235, 0.54901961,\n",
      "        0.47058824],\n",
      "       [0.59215686, 0.58431373, 0.58431373, ..., 0.47843137, 0.55294118,\n",
      "        0.5372549 ],\n",
      "       [0.59215686, 0.59215686, 0.61176471, ..., 0.42745098, 0.48235294,\n",
      "        0.57254902],\n",
      "       ...,\n",
      "       [0.7372549 , 0.7372549 , 0.4745098 , ..., 0.7254902 , 0.7254902 ,\n",
      "        0.72941176],\n",
      "       [0.7372549 , 0.73333333, 0.76862745, ..., 0.72941176, 0.71372549,\n",
      "        0.73333333],\n",
      "       [0.72941176, 0.72156863, 0.7254902 , ..., 0.75686275, 0.71764706,\n",
      "        0.72156863]])\n",
      " array([[0.90588235, 0.83137255, 0.61176471, ..., 0.17254902, 0.10588235,\n",
      "        0.0627451 ],\n",
      "       [0.89803922, 0.68627451, 0.58039216, ..., 0.10588235, 0.1372549 ,\n",
      "        0.10588235],\n",
      "       [0.83921569, 0.61176471, 0.61568627, ..., 0.10980392, 0.08627451,\n",
      "        0.10980392],\n",
      "       ...,\n",
      "       [0.94509804, 0.96078431, 0.98039216, ..., 0.22352941, 0.39607843,\n",
      "        0.57254902],\n",
      "       [0.96470588, 0.98039216, 0.98823529, ..., 0.30588235, 0.41176471,\n",
      "        0.63529412],\n",
      "       [0.98039216, 0.98431373, 0.98039216, ..., 0.34509804, 0.43137255,\n",
      "        0.59607843]])\n",
      " ...\n",
      " array([[0.29019608, 0.31764706, 0.34117647, ..., 0.74117647, 0.74901961,\n",
      "        0.75294118],\n",
      "       [0.30588235, 0.32156863, 0.34901961, ..., 0.7254902 , 0.74117647,\n",
      "        0.75686275],\n",
      "       [0.31764706, 0.3372549 , 0.36862745, ..., 0.69019608, 0.7254902 ,\n",
      "        0.75686275],\n",
      "       ...,\n",
      "       [0.35294118, 0.38823529, 0.44313725, ..., 0.75294118, 0.76470588,\n",
      "        0.77254902],\n",
      "       [0.34509804, 0.37647059, 0.44705882, ..., 0.75294118, 0.76078431,\n",
      "        0.75294118],\n",
      "       [0.34509804, 0.38039216, 0.43137255, ..., 0.7372549 , 0.73333333,\n",
      "        0.73333333]])\n",
      " array([[0.87058824, 0.89019608, 0.79607843, ..., 0.54117647, 0.51764706,\n",
      "        0.47843137],\n",
      "       [0.87058824, 0.88627451, 0.79607843, ..., 0.55686275, 0.53333333,\n",
      "        0.49803922],\n",
      "       [0.87058824, 0.88235294, 0.80784314, ..., 0.57647059, 0.56078431,\n",
      "        0.50588235],\n",
      "       ...,\n",
      "       [0.70196078, 0.70588235, 0.69411765, ..., 0.55294118, 0.54509804,\n",
      "        0.5372549 ],\n",
      "       [0.7372549 , 0.71372549, 0.69019608, ..., 0.54117647, 0.53333333,\n",
      "        0.52941176],\n",
      "       [0.70980392, 0.65882353, 0.60784314, ..., 0.53333333, 0.53333333,\n",
      "        0.5254902 ]])\n",
      " array([[0.76470588, 0.78039216, 0.80392157, ..., 0.71372549, 0.54901961,\n",
      "        0.30196078],\n",
      "       [0.75686275, 0.76862745, 0.79215686, ..., 0.77254902, 0.64705882,\n",
      "        0.41176471],\n",
      "       [0.77647059, 0.78431373, 0.8       , ..., 0.81568627, 0.76862745,\n",
      "        0.61568627],\n",
      "       ...,\n",
      "       [0.22352941, 0.28627451, 0.32941176, ..., 0.01176471, 0.07843137,\n",
      "        0.12941176],\n",
      "       [0.23921569, 0.28627451, 0.37647059, ..., 0.02352941, 0.0745098 ,\n",
      "        0.16078431],\n",
      "       [0.23921569, 0.30980392, 0.37254902, ..., 0.02352941, 0.05882353,\n",
      "        0.14901961]])]\n"
     ]
    }
   ],
   "source": [
    "kaggle_raw_path = os.path.join(os.getcwd(), \"raw_facial_data_Kaggle\",\"icml_face_data.csv\")\n",
    "\n",
    "clean_Kaggle(kaggle_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>normalized_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.27450980392156865, 0.3137254901960784, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.592156862745098, 0.5882352941176471, 0.576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.9058823529411765, 0.8313725490196079, 0.61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[0.09411764705882353, 0.12549019607843137, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.01568627450980392, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                  normalized_pixels\n",
       "0        0  [[0.27450980392156865, 0.3137254901960784, 0.3...\n",
       "1        0  [[0.592156862745098, 0.5882352941176471, 0.576...\n",
       "2        1  [[0.9058823529411765, 0.8313725490196079, 0.61...\n",
       "3        4  [[0.09411764705882353, 0.12549019607843137, 0....\n",
       "4        3  [[0.01568627450980392, 0.0, 0.0, 0.0, 0.0, 0.0..."
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(data, dataset):\n",
    "\n",
    "    emotion_labels = {0:'Angry', 1:'Fear', 2:'Happy', 3:'Neutral', 4:'Sad'}\n",
    "    num_samples = {}\n",
    "\n",
    "    for label in emotion_labels.keys():\n",
    "        num_samples[emotion_labels[label]] = len(data.loc[data.emotion==label])\n",
    "   \n",
    "    print(\"Number of\", dataset, \"images in Kaggle dataset:\\t\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Kaggle training images:  25102\n",
      "Number of Kaggle validation images:  3118\n",
      "Number of Kaggle test images:  3118\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Kaggle training images: \", len(kaggle_train_df))\n",
    "print(\"Number of Kaggle validation images: \", len(kaggle_val_df))\n",
    "print(\"Number of Kaggle test images: \", len(kaggle_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images in Kaggle dataset:\t {'Angry': 3995, 'Fear': 4097, 'Happy': 7215, 'Sad': 4830, 'Neutral': 4965}\n",
      "Number of validation images in Kaggle dataset:\t {'Angry': 467, 'Fear': 496, 'Happy': 895, 'Sad': 653, 'Neutral': 607}\n",
      "Number of test images in Kaggle dataset:\t {'Angry': 491, 'Fear': 528, 'Happy': 879, 'Sad': 594, 'Neutral': 626}\n"
     ]
    }
   ],
   "source": [
    "print_stats(kaggle_train_df, 'training')\n",
    "print_stats(kaggle_val_df, 'validation')\n",
    "print_stats(kaggle_test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aps360] *",
   "language": "python",
   "name": "conda-env-aps360-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
